{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-2-a950ab4ff21d>, line 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-a950ab4ff21d>\"\u001b[0;36m, line \u001b[0;32m82\u001b[0m\n\u001b[0;31m    def score(self, X, y):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class DiscriminantANoyau:\n",
    "\n",
    "    def __init__(self, lambda_, sigma):\n",
    "        # Cette fonction est dÃ©jÃ  codÃ©e pour vous, vous n'avez qu'Ã  utiliser\n",
    "        # les variables membres qu'elle dÃ©finit dans les autres fonctions de\n",
    "        # cette classe.\n",
    "        # Lambda et sigma sont dÃ©finis dans l'Ã©noncÃ©.\n",
    "        self.lambda_ = lambda_\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if set(y) == {0, 1}:\n",
    "            y = (y * 2) - 1\n",
    "        elif set(y) != {-1, 1}:\n",
    "            raise Exception(\"The target must be {0,1} or {-1,1}\")\n",
    "        # ImplÃ©mentez la fonction d'entraÃ®nement du classifieur, selon\n",
    "        # les Ã©quations que vous avez dÃ©veloppÃ©es dans votre rapport.\n",
    "        \n",
    "        # TODO Q3B\n",
    "        # Vous devez Ã©crire une fonction nommÃ©e evaluateFunc,\n",
    "        # qui reÃ§oit un seul argument en paramÃ¨tre, qui correspond aux\n",
    "        # valeurs des paramÃ¨tres pour lesquels on souhaite connaÃ®tre\n",
    "        # l'erreur et le gradient d'erreur pour chaque paramÃ¨tre.\n",
    "        # Cette fonction sera appelÃ©e Ã  rÃ©pÃ©tition par l'optimiseur\n",
    "        # de scipy, qui l'utilisera pour minimiser l'erreur et obtenir\n",
    "        # un jeu de paramÃ¨tres optimal.\n",
    "\n",
    "        def evaluateFunc(hypers):\n",
    "            err = 0\n",
    "            for t in range(len(y)):\n",
    "                rt = y[t]\n",
    "                h = numpy.sum(hypers[1:]*rt*K(X[s],X[t])) + hypers[0]\n",
    "                if (h * rt) <= 0:\n",
    "                    ind_mal_classe.append(t)\n",
    "                    err += numpy.sum(1-rt*h)\n",
    "                err += self.lambda_ * numpy.sum(hypers[1:])\n",
    "                    \n",
    "            return err, grad\n",
    "\n",
    "        # TODO Q3B\n",
    "        # Initialisez alÃ©atoirement les paramÃ¨tres alpha et omega0\n",
    "        # (l'optimiseur requiert un \"initial guess\", et nous ne pouvons pas\n",
    "        # simplement n'utiliser que des zÃ©ros pour diffÃ©rentes raisons).\n",
    "        alpha = np.random.rand(X.shape[1])\n",
    "        alpha = np.array(alpha)\n",
    "        wo = np.random.rand(1)\n",
    "        wo = np.array(w0)\n",
    "        # Stochez ces valeurs initiales alÃ©atoires dans un array numpy nommÃ©\n",
    "        # \"params\"\n",
    "        params = numpy.concatenate((w0,alpha),axis=0)        \n",
    "        # DÃ©terminez Ã©galement les bornes Ã  utiliser sur ces paramÃ¨tres\n",
    "        # et stockez les dans une variable nommÃ©e \"bounds\".\n",
    "        # Indice : les paramÃ¨tres peuvent-ils avoir une valeur maximale (au-\n",
    "        # dessus de laquelle ils ne veulent plus rien dire)? Une valeur\n",
    "        # minimale? RÃ©fÃ©rez-vous Ã  la documentation de fmin_l_bfgs_b\n",
    "        # pour savoir comment indiquer l'absence de bornes.\n",
    "        bounds = [(None,None) for i in range(3)]        \n",
    "        # Ã€ ce stade, trois choses devraient Ãªtre dÃ©finies :\n",
    "        # - Une fonction d'Ã©valuation nommÃ©e evaluateFunc, capable de retourner\n",
    "        #   l'erreur et le gradient d'erreur pour chaque paramÃ¨tre pour une\n",
    "        #   configuration de paramÃ¨tres alpha et omega_0 donnÃ©e.\n",
    "        # - Un tableau numpy nommÃ© params de mÃªme taille que le nombre de\n",
    "        #   paramÃ¨tres Ã  entraÃ®ner.\n",
    "        # - Une liste nommÃ©e bounds contenant les bornes que l'optimiseur doit\n",
    "        #   respecter pour chaque paramÃ¨tre\n",
    "        # On appelle maintenant l'optimiseur avec ces informations et on stocke\n",
    "        # les valeurs optimisÃ©es dans params\n",
    "        _times.append(time.time())\n",
    "        params, minval, infos = fmin_l_bfgs_b(\n",
    "            evaluateFunc, params, bounds=bounds)\n",
    "        _times.append(time.time())\n",
    "        checkTime(TMAX_FIT, \"Entrainement\")\n",
    "\n",
    "        # On affiche quelques statistiques\n",
    "        print(\"EntraÃ®nement terminÃ© aprÃ¨s {it} itÃ©rations et \"\n",
    "              \"{calls} appels Ã  evaluateFunc\".format(it=infos['nit'], calls=infos['funcalls']))\n",
    "        print(\"\\tErreur minimale : {:.5f}\".format(minval))\n",
    "        print(\"\\tL'algorithme a convergÃ©\" if infos['warnflag']\n",
    "              == 0 else \"\\tL'algorithme n'a PAS convergÃ©\")\n",
    "        print(\"\\tGradients des paramÃ¨tres Ã  la convergence (ou Ã  l'Ã©puisement des ressources) :\")\n",
    "        print(infos['grad'])\n",
    "\n",
    "        # TODO Q3B\n",
    "        # Stockez les paramÃ¨tres optimisÃ©s de la faÃ§on suivante\n",
    "        # - Le vecteur alpha dans self.alphas\n",
    "        # - Le biais omega0 dans self.w0\n",
    "        self.alphas = params[1:]\n",
    "        self.w0 = params[0]\n",
    "        # On retient Ã©galement le jeu d'entraÃ®nement, qui pourra\n",
    "        # vous Ãªtre utile pour les autres fonctions Ã  implÃ©menter\n",
    "        self.X, self.y = X, y\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO Q3B\n",
    "        # ImplÃ©mentez la fonction de prÃ©diction\n",
    "        # Vous pouvez supposer que fit() a prÃ©alablement Ã©tÃ© exÃ©cutÃ©\n",
    "        # et que les variables membres alphas, w0, X et y existent.\n",
    "        # N'oubliez pas que ce classifieur doit retourner -1 ou 1\n",
    "\n",
    "    def score(self, X, y):\n",
    "        # TODO Q3B\n",
    "        # ImplÃ©mentez la fonction retournant le score (accuracy)\n",
    "        # du classifieur sur les donnÃ©es reÃ§ues en argument.\n",
    "        # Vous pouvez supposer que fit() a prÃ©alablement Ã©tÃ© exÃ©cutÃ©\n",
    "        # Indice : rÃ©utiliser votre implÃ©mentation de predict() rÃ©duit de\n",
    "        # beaucoup la taille de cette fonction!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q3B\n",
    "    # CrÃ©ez le jeu de donnÃ©es Ã  partir de la fonction make_moons, tel que\n",
    "    # demandÃ© dans l'Ã©noncÃ©\n",
    "    # N'oubliez pas de vous assurer que les valeurs possibles de y sont\n",
    "    # bel et bien -1 et 1, et non 0 et 1!\n",
    "\n",
    "    # TODO Q3B\n",
    "    # SÃ©parez le jeu de donnÃ©es en deux parts Ã©gales, l'une pour l'entraÃ®nement\n",
    "    # et l'autre pour le test\n",
    "\n",
    "    _times.append(time.time())\n",
    "    # TODO Q3B\n",
    "    # Une fois les paramÃ¨tres lambda et sigma de votre classifieur optimisÃ©s,\n",
    "    # crÃ©ez une instance de ce classifieur en utilisant ces paramÃ¨tres optimaux,\n",
    "    # et calculez sa performance sur le jeu de test.\n",
    "\n",
    "    # TODO Q3B\n",
    "    # CrÃ©ez ici une grille permettant d'afficher les rÃ©gions de\n",
    "    # dÃ©cision pour chaque classifieur\n",
    "    # Indice : numpy.meshgrid pourrait vous Ãªtre utile ici\n",
    "    # Par la suite, affichez les rÃ©gions de dÃ©cision dans la mÃªme figure\n",
    "    # que les donnÃ©es de test.\n",
    "    # Note : utilisez un pas de 0.02 pour le meshgrid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_moons(n_samples=1000, shuffle=True, noise=0.3, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84286028 0.46480512]\n",
      "[0.77922928]\n"
     ]
    }
   ],
   "source": [
    "alpha = numpy.random.rand(X.shape[1])\n",
    "alpha = numpy.array(alpha)\n",
    "print(alpha)\n",
    "w0 = numpy.random.rand(1)\n",
    "w0 = numpy.array(w0)\n",
    "print(w0)\n",
    "# Stochez ces valeurs initiales alÃ©atoires dans un array numpy nommÃ©\n",
    "# \"params\"\n",
    "params = numpy.concatenate((w0,alpha),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77922928, 0.84286028, 0.46480512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(None,None) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, None), (None, None), (None, None)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
