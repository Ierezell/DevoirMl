{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import numpy\n",
    "import warnings\n",
    "from io import BytesIO\n",
    "from http.client import HTTPConnection\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Nous ne voulons pas avoir ce type d'avertissement, qui\n",
    "# n'est pas utile dans le cadre de ce devoir\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchPendigits():\n",
    "    \"\"\"\n",
    "    Cette fonction télécharge le jeu de données pendigits et le\n",
    "    retourne sous forme de deux tableaux numpy. Le premier élément\n",
    "    retourné par cette fonction est un tableau de 10992x16 qui\n",
    "    contient les samples; le second élément est un vecteur de 10992\n",
    "    qui contient les valeurs cible (target).\n",
    "    \"\"\"\n",
    "    host = 'vision.gel.ulaval.ca'\n",
    "    url = '/~cgagne/enseignement/apprentissage/A2018/travaux/ucipendigits.npy'\n",
    "    connection = HTTPConnection(host, port=80, timeout=10)\n",
    "    connection.request('GET', url)\n",
    "\n",
    "    rep = connection.getresponse()\n",
    "    if rep.status != 200:\n",
    "        print(\"ERREUR : impossible de télécharger le jeu de données UCI Pendigits! Code d'erreur {}\".format(rep.status))\n",
    "        print(\"Vérifiez que votre ordinateur est bien connecté à  Internet.\")\n",
    "        return\n",
    "    stream = BytesIO(rep.read())\n",
    "    dataPendigits = numpy.load(stream)\n",
    "    return dataPendigits[:, :-1].astype('float32'), dataPendigits[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = fetchPendigits()\n",
    "X = minmax_scale(X)\n",
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-(5000/len(X)), random_state=666, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classifieurs :  9\n",
      "Error {1: 0.01570106654160775, 2: 0.01570106654160775, 3: 0.01705348860678468, 4: 0.016466322043992627, 5: 0.01698930189956879, 6: 0.017188776769530692, 7: 0.019444678751882122, 8: 0.019887189141925235, 9: 0.022253831911906326}\n",
      "argminlast K =  1\n",
      "argminmoy K =  1.8666666666666667\n",
      "Param retenu K =  2\n",
      "minErrorKnn 0.01570106654160775\n",
      "temps :  41.70761156082153\n"
     ]
    }
   ],
   "source": [
    "_times = []\n",
    "_times.append(time.time())\n",
    "\n",
    "listK = list(range(1,10))\n",
    "listKnn = list(map(lambda k:KNeighborsClassifier(n_neighbors=k, weights='distance'),listK))\n",
    "ErrorKnn = {listKnn[i].n_neighbors:0 for i in range(len(listKnn))}\n",
    "print(\"Nombre de classifieurs : \",len(listKnn))\n",
    "\n",
    "argMinKnn = 0 \n",
    "Nb_boucle = 30\n",
    "for _ in range(Nb_boucle):\n",
    "    kf = KFold(n_splits=3, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_train = X_train[train_index]\n",
    "        X_train_test = X_train[test_index]\n",
    "        y_train_train = y_train[train_index]\n",
    "        y_train_test = y_train[test_index]\n",
    "        for i in range(len(listKnn)):\n",
    "            listKnn[i].fit(X_train_train, y_train_train)\n",
    "            ErrorKnn[listKnn[i].n_neighbors] += 1 - listKnn[i].score(X_train_test, y_train_test)\n",
    "    ErrorKnn = {k: v / kf.get_n_splits(X_train) for k, v in ErrorKnn.items()}\n",
    "    minErrorKnn = min([ErrorKnn[i] for i in ErrorKnn.keys()])\n",
    "    argmin = list(ErrorKnn.keys())[list(ErrorKnn.values()).index(minErrorKnn)]\n",
    "    argMinKnn += argmin\n",
    "argMinKnn /= Nb_boucle\n",
    "print(\"Error\",ErrorKnn)\n",
    "print(\"argminlast K = \",argmin)\n",
    "print(\"argminmoy K = \",argMinKnn)\n",
    "argMinKnn = round(argMinKnn)\n",
    "print(\"Param retenu K = \",argMinKnn)\n",
    "print(\"AccKnn\", 1-minErrorKnn)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "X_train_train, X_train_test, y_train_train,y_train_test = train_test_split(X, y, test_size=50, random_state=666, shuffle=True)\n",
    "for i in range(len(listKnn)):\n",
    "        listKnn[i].fit(X_train_train, y_train_train)\n",
    "        ErrorKnn[listKnn[i].C, listKnn[i].gamma] = 1 - listKnn[i].score(X_train_test, y_train_test)\n",
    "minErrorKnn = min([ErrorKnn[i] for i in ErrorKnn.keys()])\n",
    "argMinKnn = list(ErrorKnn.keys())[list(ErrorKnn.values()).index(minErrorKnn)]\n",
    "print(\"Error\",ErrorKnn)\n",
    "print(\"argmin\",argMinKnn)\n",
    "print(\"minErrorKnn\", minErrorKnn)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "_times.append(time.time())\n",
    "\n",
    "print(\"temps : \", _times[-1] - _times[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classifieurs :  48\n",
      "argmin C, g =  (60, 0.6973101806565765)\n",
      "minErrorSvc 0.0036000000000000034\n",
      "temps :  239.39085578918457\n"
     ]
    }
   ],
   "source": [
    "_times = []\n",
    "_times.append(time.time())\n",
    "\n",
    "MatrixSigma =  numpy.array(pairwise_distances(X_train))\n",
    "SigmaMin = (MatrixSigma + numpy.identity(MatrixSigma.shape[0])*1e10).min()\n",
    "SigmaParam = numpy.array([SigmaMin*(2**i) for i in range(6)])\n",
    "listGamma = 1.0/(2*(SigmaParam**2))\n",
    "#listC = [10**n for n in range(-5,6)]\n",
    "listC = list(range(60,100,5))\n",
    "listSVC = []\n",
    "ErrorSVC = {(c,g):0 for c in listC for g in listGamma}\n",
    "\n",
    "for g in listGamma:\n",
    "    for c in listC:\n",
    "        listSVC.append(SVC(kernel='rbf', C=c, gamma=g))\n",
    "\n",
    "print(\"Nombre de classifieurs : \",len(listSVC))\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_train = X_train[train_index]\n",
    "    X_train_test = X_train[test_index]\n",
    "    y_train_train = y_train[train_index]\n",
    "    y_train_test = y_train[test_index]\n",
    "    for i in range(len(listSVC)):\n",
    "        listSVC[i].fit(X_train_train, y_train_train)\n",
    "        ErrorSVC[listSVC[i].C, listSVC[i].gamma] += 1 - listSVC[i].score(X_train_test, y_train_test)\n",
    "ErrorSVC = {k: v / kf.get_n_splits(X_train) for k, v in ErrorSVC.items()}\n",
    "minErrorSVC = min([ErrorSVC[i] for i in ErrorSVC.keys()])\n",
    "argMinSVC = list(ErrorSVC.keys())[list(ErrorSVC.values()).index(minErrorSVC)]\n",
    "#print(\"Error\",ErrorSVC)\n",
    "print(\"argmin C, g = \",argMinSVC)\n",
    "print(\"AccSvc\", 1-minErrorSVC)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "X_train_train, X_train_test, y_train_train,y_train_test = train_test_split(X, y, test_size=50, random_state=666, shuffle=True)\n",
    "for i in range(len(listSVC)):\n",
    "        listSVC[i].fit(X_train_train, y_train_train)\n",
    "        ErrorSVC[listSVC[i].C, listSVC[i].gamma] = 1 - listSVC[i].score(X_train_test, y_train_test)\n",
    "minErrorSVC = min([ErrorSVC[i] for i in ErrorSVC.keys()])\n",
    "argMinSVC = list(ErrorSVC.keys())[list(ErrorSVC.values()).index(minErrorSVC)]\n",
    "print(\"Error\",ErrorSVC)\n",
    "print(\"argmin\",argMinSVC)\n",
    "print(\"minErrorSVC\", minErrorSVC)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "_times.append(time.time())\n",
    "\n",
    "print(\"temps : \", _times[-1] - _times[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 32, 48]\n",
      "[10, 20, 30]\n",
      "[(16,), (32,), (48,), (16, 10), (16, 20), (16, 30), (32, 10), (32, 20), (32, 30), (48, 10), (48, 20), (48, 30)]\n",
      "Nombre de classifieurs :  12\n",
      "argmin Couche cachée 1, couche cachée 2 =  (32, 30)\n",
      "minErrorMLP 0.04619976364871092\n",
      "temps :  83.56617832183838\n"
     ]
    }
   ],
   "source": [
    "_times = []\n",
    "_times.append(time.time())\n",
    "\n",
    "Nfeat = len(X[0])\n",
    "Nsortie = len(set(y_train))\n",
    "listHidLay1 = [Nfeat,2*Nfeat,3*Nfeat]\n",
    "listHidLay2 = [Nsortie,2*Nsortie,3*Nsortie]\n",
    "listHidLay = [tuple(listHidLay1[i:i+1]) for i in range(len(listHidLay1))]+[(x,y) for x in listHidLay1 for y in listHidLay2] \n",
    "print(listHidLay1)\n",
    "print(listHidLay2)\n",
    "print(listHidLay)\n",
    "print(\"Nombre de classifieurs : \",len(listHidLay))\n",
    "listMLP = list(map(lambda HidLay:MLPClassifier(hidden_layer_sizes=HidLay) , listHidLay))\n",
    "ErrorMLP = {listMLP[i].hidden_layer_sizes:0 for i in range(len(listHidLay))}\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_train = X_train[train_index]\n",
    "    X_train_test = X_train[test_index]\n",
    "    y_train_train = y_train[train_index]\n",
    "    y_train_test = y_train[test_index]\n",
    "    for i in range(len(listMLP)):\n",
    "        listMLP[i].fit(X_train_train, y_train_train)\n",
    "        ErrorMLP[listMLP[i].hidden_layer_sizes] += 1 - listMLP[i].score(X_train_test, y_train_test)\n",
    "#ErrorMLP = {k: v / kf.get_n_splits(X_train) for k, v in ErrorMLP.items()}\n",
    "minErrorMLP = min([ErrorMLP[i] for i in ErrorMLP.keys()])\n",
    "argMinMLP = list(ErrorMLP.keys())[list(ErrorMLP.values()).index(minErrorMLP)]\n",
    "#print(\"Error\",ErrorMLP)\n",
    "print(\"argmin Couche cachée 1, couche cachée 2 = \",argMinMLP)\n",
    "print(\"AccMLP\", 1-minErrorMLP)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "X_train_train, X_train_test, y_train_train,y_train_test = train_test_split(X, y, test_size=50, shuffle=True)\n",
    "for i in range(len(listMLP)):\n",
    "        listMLP[i].fit(X_train_train, y_train_train)\n",
    "        ErrorMLP[listMLP[i].hidden_layer_sizes] = 1 - listMLP[i].score(X_train_test, y_train_test)\n",
    "minErrorMLP = min([ErrorMLP[i] for i in ErrorMLP.keys()])\n",
    "argMinMLP = list(ErrorMLP.keys())[list(ErrorMLP.values()).index(minErrorMLP)]\n",
    "print(\"Error\",ErrorMLP)\n",
    "print(\"argmin\",argMinMLP)\n",
    "print(\"minErrorMLP\", minErrorMLP)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "_times.append(time.time())\n",
    "\n",
    "print(\"temps : \", _times[-1] - _times[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ErrorMLP :  0.014854615908359925\n",
      "ErrorSVC :  0.006008206616253653\n",
      "ErrorKnn :  0.010013352807918662\n"
     ]
    }
   ],
   "source": [
    "ClassMLP = MLPClassifier(hidden_layer_sizes=argMinMLP)\n",
    "ClassSVC = SVC(kernel='rbf', C=argMinSVC[0], gamma=argMinSVC[1])\n",
    "ClassKnn = KNeighborsClassifier(n_neighbors=argMinKnn)\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "ErrorKnn, ErrorSVC,ErrorMLP = 0, 0, 0\n",
    "for train_index, test_index in kf.split(X_test):\n",
    "    X_test_train = X_test[train_index]\n",
    "    X_test_test = X_test[test_index]\n",
    "    y_test_train = y_test[train_index]\n",
    "    y_test_test = y_test[test_index]\n",
    "    ClassMLP.fit(X_test_train, y_test_train)\n",
    "    ClassSVC.fit(X_test_train, y_test_train)\n",
    "    ClassKnn.fit(X_test_train, y_test_train)\n",
    "    ErrorMLP += 1 - ClassMLP.score(X_test_test, y_test_test)\n",
    "    ErrorSVC += 1 - ClassSVC.score(X_test_test, y_test_test)\n",
    "    ErrorKnn += 1 - ClassKnn.score(X_test_test, y_test_test)\n",
    "\n",
    "print(\"ErrorMLP : \",ErrorMLP/kf.get_n_splits(X_test))\n",
    "print(\"ErrorSVM : \",ErrorSVC/kf.get_n_splits(X_test))\n",
    "print(\"ErrorKnn : \",ErrorKnn/kf.get_n_splits(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
