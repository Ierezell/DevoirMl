{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot, patches\n",
    "\n",
    "from sklearn.datasets import make_classification, load_breast_cancer, load_iris\n",
    "from sklearn.preprocessing import minmax_scale, normalize\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.model_selection import KFold, LeaveOneOut\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminantLineaire:\n",
    "    def __init__(self, eta=1e-2, epsilon=1e-3, max_iter=1000):\n",
    "        # Cette fonction est déjà  codée pour vous, vous n'avez qu'à  utiliser\n",
    "        # les variables membres qu'elle définit dans les autres fonctions de\n",
    "        # cette classe.\n",
    "        self.eta = eta\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if set(y) == {0, 1}:\n",
    "            y = (y * 2) - 1\n",
    "        elif set(y) != {-1, 1}:\n",
    "            raise Exception(\"The target must be {0,1} or {-1,1}\")\n",
    "        # Implémentez la fonction d'entraînement du classifieur, selon\n",
    "        # les équations que vous avez développées dans votre rapport.\n",
    "\n",
    "        # On initialise les poids aléatoirement\n",
    "        w = np.random.rand(X.shape[1] + 1)\n",
    "        # Je prend w[0] = w0 et w[1:] tout le reste des poids\n",
    "        # TODO Q2B\n",
    "        # Vous devez ici implémenter l'entraînement.\n",
    "        # Celui-ci devrait être contenu dans la boucle suivante, qui se répète\n",
    "        # self.max_iter fois\n",
    "        # Vous êtes libres d'utiliser les noms de variable de votre choix, sauf\n",
    "        # pour les poids qui doivent être contenus dans la variable w définie\n",
    "        # plus haut\n",
    "        Err_prec = 1e10\n",
    "        for i in range(self.max_iter):\n",
    "            print(\"boucle : \", i)\n",
    "            num_mal_classe = []\n",
    "            ind_mal_classe = []\n",
    "\n",
    "            for j in range(len(y)):\n",
    "                hxjw = np.dot(w[1:], X[j]) + w[0]\n",
    "                Y = y[j] * hxjw\n",
    "                if Y <= 0:\n",
    "                    num_mal_classe.append(y[j] - hxjw)\n",
    "                    ind_mal_classe.append(j)\n",
    "            ind_mal_classe = np.array(ind_mal_classe)\n",
    "            if ind_mal_classe.size:\n",
    "                normeX = np.linalg.norm(X[ind_mal_classe])**2\n",
    "                num = np.array(num_mal_classe)\n",
    "                Err = np.array(0.5 * sum(num**2 / normeX))\n",
    "                deltawi = self.eta * \\\n",
    "                    [sum(np.dot(X[ind_mal_classe][:, i], (num / (normeX))))\n",
    "                     for i in range()]\n",
    "                deltaw0 = self.eta * sum(num / normeX)\n",
    "            else:\n",
    "                Err = 0\n",
    "                deltawi = 0\n",
    "                deltaw0 = 0\n",
    "\n",
    "            # condition d'arrêt :\n",
    "            print(\"Err : \", Err)\n",
    "            if Err_prec - Err < self.epsilon:\n",
    "                print(\"Les poids ont convergés\")\n",
    "                break\n",
    "            else:\n",
    "                Err_prec = Err\n",
    "            print(\"dela : \", deltawi)\n",
    "            w[1:] += deltawi\n",
    "            w[0] += deltaw0\n",
    "\n",
    "            # à ce stade, la variable w devrait contenir les poids entraînés\n",
    "            # On les copie dans une variable membre pour les conserver\n",
    "            print(\"poids : \", w[1:])\n",
    "            print(\"Base : \", w[0])\n",
    "            print()\n",
    "        self.w = w\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO Q2B\n",
    "        # Implémentez la fonction de prédiction\n",
    "        # Vous pouvez supposer que fit() a préalablement été exécuté\n",
    "        return np.array(\n",
    "            [1 if self.w[1:].dot(x) + self.w[0] >= 0\n",
    "             else 0\n",
    "             for x in X])\n",
    "\n",
    "    def score(self, X, y):\n",
    "        if set(y) == {0, 1}:\n",
    "            y = (y * 2) - 1\n",
    "        elif set(y) != {-1, 1}:\n",
    "            raise Exception(\"The target must be {0,1} or {-1,1}\")\n",
    "        # TODO Q2B\n",
    "        # Implémentez la fonction retournant le score (précision / accuracy)\n",
    "        # du classifieur sur les données reçues en argument.\n",
    "        # Vous pouvez supposer que fit() a préalablement été exécuté\n",
    "        # Indice : réutiliser votre implémentation de predict() réduit de\n",
    "        # beaucoup la taille de cette fonction!\n",
    "\n",
    "        # Question 2B\n",
    "        # Implémentation du classifieur un contre tous utilisant le\n",
    "        # discriminant linéaire défini plus haut\n",
    "        return sum([self.predict(X)[i] == y[i]\n",
    "                    for i in range(len(y))]) / len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifieurUnContreTous:\n",
    "    def __init__(self, n_classes, **kwargs):\n",
    "        # Cette fonction est déjà  codée pour vous, vous n'avez qu'à  utiliser\n",
    "        # les variables membres qu'elle définit dans les autres fonctions de\n",
    "        # cette classe.\n",
    "        self.n_classes = n_classes\n",
    "        self.estimators = [DiscriminantLineaire(\n",
    "            **kwargs) for c in range(n_classes)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # TODO Q2C\n",
    "        # Implémentez ici une approche un contre tous, oà¹ chaque classifieur\n",
    "        # (contenu dans self.estimators) est entraîné à  distinguer une seule\n",
    "        # classe versus toutes les autres\n",
    "        for i in range(self.n_classes):\n",
    "            target = y - i\n",
    "            target[numpy.where(target != 0)] = 1\n",
    "            # target = (target*2)-1 pour mettre entre -1 et 1\n",
    "            # mais déjà implémenté dans le fit de Disciminant linéraire\n",
    "            self.estimators[i].fit(X, target)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO Q2C\n",
    "        # Implémentez ici la prédiction utilisant l'approche un contre tous\n",
    "        # Vous pouvez supposer que fit() a préalablement été exécuté\n",
    "        classes = []\n",
    "        for x in X:\n",
    "            Hall = [est.w[1:].dot(x) + est.w[0] for est in self.estimators]\n",
    "            classes.append(numpy.argmax(Hall))\n",
    "        return classes\n",
    "\n",
    "    def score(self, X, y):\n",
    "        # TODO Q2C\n",
    "        # Implémentez ici le calcul du score utilisant l'approche un contre\n",
    "        # tous. Ce score correspond à  la précision (accuracy) moyenne.\n",
    "        # Vous pouvez supposer que fit() a préalablement été exécuté\n",
    "        return sum([self.predict(X)[i] == y[i] for i in range(len(y))])/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boucle :  0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "range expected 1 arguments, got 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e62c75fc7e51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminantLineaire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1a3f7c8f3407>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mErr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormeX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 deltawi = self.eta *                     [sum(np.dot(X[ind_mal_classe][:, i], (num / (normeX))))\n\u001b[0;32m---> 46\u001b[0;31m                      for i in range()]\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mdeltaw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormeX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: range expected 1 arguments, got 0"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           n_clusters_per_class=1)\n",
    "\n",
    "\n",
    "clf = DiscriminantLineaire(epsilon=1e-2)\n",
    "clf.fit(X, y)\n",
    "fig, sfig = pyplot.subplots(1, 1, sharex=True, sharey=True)\n",
    "\n",
    "pas = 100\n",
    "x1 = numpy.linspace(X[:, 0].min(), X[:, 0].max(), pas)\n",
    "x2 = numpy.linspace(X[:, 1].min(), X[:, 1].max(), pas)\n",
    "absc, ordon = numpy.meshgrid(x1, x2)\n",
    "sfig.scatter(absc, ordon, alpha=0.05, s=20,\n",
    "             c=[\"bgrcmykw\"[i] for i in clf.predict(\n",
    "                 numpy.c_[absc.ravel(), ordon.ravel()])])\n",
    "sfig.scatter(X[:, 0], X[:, 1], c=[\"bgrcmykw\"[i] for i in y])\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.rand(X.shape[1] + 1)\n",
    "num_mal_classe = []\n",
    "ind_mal_classe = []\n",
    "for j in range(len(y)):\n",
    "    hxjw = np.dot(w[1:], X[j]) + w[0]\n",
    "    Y = y[j] * hxjw\n",
    "    if Y <= 0:\n",
    "        num_mal_classe.append(y[j] - hxjw)\n",
    "        ind_mal_classe.append(j)\n",
    "ind_mal_classe = np.array(ind_mal_classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-85d86292ac56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mErr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormeX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m deltawi = 0.45 *     [sum(np.dot(X[ind_mal_classe][:, i], (num / (normeX))))\n\u001b[0;32m----> 5\u001b[0;31m      for i in range(X.shape[1])]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-85d86292ac56>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mErr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormeX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m deltawi = 0.45 *     [sum(np.dot(X[ind_mal_classe][:, i], (num / (normeX))))\n\u001b[0;32m----> 5\u001b[0;31m      for i in range(X.shape[1])]\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "normeX = np.linalg.norm(X[ind_mal_classe])**2\n",
    "num = np.array(num_mal_classe)\n",
    "Err = np.array(0.5 * sum(num**2 / normeX))\n",
    "deltawi = 0.45 * \\\n",
    "    [sum(np.dot(X[ind_mal_classe][:, i], (num / (normeX))))\n",
    "     for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2452442 , -1.09082819, -2.48536686, -0.98027382, -1.46038448,\n",
       "        0.08652863, -2.47693199, -0.47956659,  0.11278721, -1.31546898,\n",
       "       -1.56306676, -0.35289364, -1.59552161, -2.08550484, -2.49207855,\n",
       "        0.15685036,  0.50986526, -2.97213229,  0.13892327, -0.46901274,\n",
       "       -2.12840186, -0.63896116,  0.52051325, -0.63171566, -0.98153321,\n",
       "       -2.65858061, -1.11961035, -1.16722561, -0.19125828, -1.71290441,\n",
       "       -1.38160063, -1.43662287, -1.58684661, -1.23260598, -1.08206529,\n",
       "       -1.9786807 , -1.48209328,  0.0162584 , -0.73971063, -2.2988313 ,\n",
       "       -1.94156856,  0.58365125, -2.78451936, -0.65602586, -0.1545911 ,\n",
       "       -1.19867626, -1.30801144,  0.2437647 ,  0.75680413,  0.7467427 ,\n",
       "        0.21206046, -0.92779235, -2.0803194 , -0.46411589,  1.22090053,\n",
       "       -0.03679753, -0.78479731, -0.51251437, -1.36260571, -1.79359204,\n",
       "       -1.42532252, -1.23197245, -2.79061175, -0.23247328,  0.02102749])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plop = [np.dot(X[ind_mal_classe][:,i],(num/normeX)) for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.11834317217656982, -0.26674875957511435]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "plop = np.array(plop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11834317, -0.26674876])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plop *= 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04733727, -0.1066995 ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([-0.0069122 , -0.00353473])\n",
    "delta = np.array([0.2535428  ,0.85162685])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "w += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
       "        0.41886396],\n",
       "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
       "        0.22287813],\n",
       "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
       "        0.21343303],\n",
       "       ...,\n",
       "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
       "        0.1519087 ],\n",
       "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
       "        0.45231536],\n",
       "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
       "        0.10068215]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_scale(X.data,feature_range=(0, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.92541486e-03, 4.57286305e-03, 5.40989964e-02, ...,\n",
       "        1.16920795e-04, 2.02695018e-04, 5.23808686e-05],\n",
       "       [8.66575595e-03, 7.48616836e-03, 5.59882822e-02, ...,\n",
       "        7.83583182e-05, 1.15852352e-04, 3.75024596e-05],\n",
       "       [9.36668268e-03, 1.01087865e-02, 6.18419883e-02, ...,\n",
       "        1.15596947e-04, 1.71873157e-04, 4.16624718e-05],\n",
       "       ...,\n",
       "       [1.16438847e-02, 1.96964025e-02, 7.59658259e-02, ...,\n",
       "        9.94640269e-05, 1.55579134e-04, 5.48525170e-05],\n",
       "       [9.23020523e-03, 1.31418408e-02, 6.27743569e-02, ...,\n",
       "        1.18738077e-04, 1.83125480e-04, 5.55604587e-05],\n",
       "       [2.31098880e-02, 7.30820427e-02, 1.42709515e-01, ...,\n",
       "        0.00000000e+00, 8.55006294e-04, 2.09626935e-04]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(X.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(0, 1)\n",
      "(1, 0)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    if bin(i)[-2] == 'b':\n",
    "        nb_subplot = int('0'),int(bin(i)[-1])\n",
    "    else:\n",
    "        nb_subplot = int(bin(i)[-2]),int(bin(i)[-1])\n",
    "    print(nb_subplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X, y = minmax_scale(data.data, feature_range=(0, 1)), data.target\n",
    "\n",
    "# TODO Q2D\n",
    "# Comparez les diverses approches demandées dans l'énoncé sur Iris\n",
    "# Pour utilisez votre discriminant linéaire, utilisez l'approche Un Contre\n",
    "# Tous implémenté au 2C.\n",
    "# Initialisez vos discriminants linéaires avec les paramètres suivants :\n",
    "# DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000)\n",
    "# Pour les autres approches, conservez les valeurs par défaut\n",
    "# N'oubliez pas que l'évaluation doit être faite par une validation\n",
    "# croisée à  K=3 plis!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [ClassifieurUnContreTous(len(X[0]), eta=1e-4,\n",
    "                                epsilon=1e-6, max_iter=10000),\n",
    "        LinearDiscriminantAnalysis(),\n",
    "        Perceptron(),\n",
    "        LogisticRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, random_state=666, shuffle=False)\n",
    "ErrorsTest = [0] * 4\n",
    "ErrorsTrain = [0] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clfs)):\n",
    "    avgErrorTest = 0\n",
    "    avgErrorTrain = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "for i in set([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]):\n",
    "    target = y - i\n",
    "    target[np.where(target != 0)] = 1\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    target = y.copy()\n",
    "    target[np.where(target == i)] = 0\n",
    "    target[np.where(target != 0)] = 1\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boucle :  0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "range expected 1 arguments, got 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-d0b5b5a09372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mclfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mavgErrorTrain\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mavgErrorTest\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-36f757142bc8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# target = (target*2)-1 pour mettre entre -1 et 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# mais déjà implémenté dans le fit de Disciminant linéraire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1a3f7c8f3407>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mErr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormeX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 deltawi = self.eta *                     [sum(np.dot(X[ind_mal_classe][:, i], (num / (normeX))))\n\u001b[0;32m---> 46\u001b[0;31m                      for i in range()]\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mdeltaw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormeX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: range expected 1 arguments, got 0"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in range(len(clfs)):\n",
    "    avgErrorTest = 0\n",
    "    avgErrorTrain = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index]-1, y[test_index]-1\n",
    "        clfs[i].fit(X_train, y_train)\n",
    "        avgErrorTrain += 1 - clfs[i].score(X_train, y_train)\n",
    "        avgErrorTest += 1 - clfs[i].score(X_test, y_test)\n",
    "    ErrorsTest[i] = avgErrorTest / 3\n",
    "    ErrorsTrain[i] = avgErrorTrain / 3\n",
    "\n",
    "print(\"Erreurs Iris Train (Own, Linear, Perceptron, Logistic) :\\n\",\n",
    "      ErrorsTrain)\n",
    "print(\"Erreurs Iris Test (Own, Linear, Perceptron, Logistic) :\\n\",\n",
    "      ErrorsTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 18\n",
      "2 19\n",
      "3 20\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip([1,2,3],[18,19,20]):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
